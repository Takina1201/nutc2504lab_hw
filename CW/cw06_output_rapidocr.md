# 一、摘要

大型語言模型(Large Language Models)在各種領域中的許多應用上嶄露頭角,逐漸成為普羅大眾日常生活的一部分。然而,LLM 的幻覺問題(Hallucination)卻會造成真假難辨的生成結果,造成使用者對 LLM 產生疑慮,進而影響 LLM 各種應用的持續推廣。

## 二、研究動機與研究問題

(一)、研究動機
自ChatGPT 問世以來,大型語言模型(Large Language Models,以下簡稱LLM)迅速地崛起...

(二)、研究問題
透過理解大型語言模型的運作原理、幻覺問題可能的成因與RAG的優勢後,我們決定藉由改良 RAG的運作流程來進一步提升這個框架在特定問題上的表現。

## 五、結果與討論

以下是使用 all-MiniLM-L6-v2 作為 Embedding model,在不同問題下,更改不同 Top-K得出的實驗結果。

| Top-K | Precision | AP | NDCG |
|---|---|---|---|
| 5 | 1 | 1 | 1 |
| 10 | 0.9 | 0.96 | 0.93 |
| 20 | 0.65 | 0.93 | 0.75 |

*表格 1: Covid-19 Wiki Q1 測試結果*

從實驗數據中可以看出,當Top-K設為5或10時,模型在 Precision 和 NDCG 指標上均表現出較高的分數...