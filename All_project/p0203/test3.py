from openai import OpenAI

# 1. åˆå§‹åŒ–è¨­å®š
client = OpenAI(
    base_url="https://ws-02.wade0426.me/v1", 
    api_key="vllm-token"
)

# 2. è¨­å®šæ¸¬è©¦ç”¨çš„ Prompt å’Œä¸åŒçš„æº«åº¦å€¼
prompt = "è«‹ç”¨100å­—å½¢å®¹ã€äººå·¥æ™ºæ…§ã€ã€‚"
temps = [0.1, 1.5]  # 0.1 å¾ˆå†·éœ (å›ºå®š), 1.5 å¾ˆç™¼æ•£ (å‰µæ„/æ··äº‚)

print(f"æç¤ºè©: {prompt}\n")

# 3. è¿´åœˆæ¸¬è©¦ä¸åŒæº«åº¦
for t in temps:
    print(f"â¡ æ¸¬è©¦ Temperature = {t} ...")
    try:
        response = client.chat.completions.create(
            model="google/gemma-3-27b-it",  # ä½¿ç”¨ç›®å‰å¯ç”¨çš„æ¨¡å‹
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=t,      # é€™è£¡å¸¶å…¥è¿´åœˆç›®å‰çš„æº«åº¦
            max_tokens=200      # ç¨å¾®åŠ é•·ä¸€é»è®“å®ƒç™¼æ®
        )
        
        # é¡¯ç¤ºçµæœ
        print(f"ğŸ¤– å›è¦†: {response.choices[0].message.content}\n" + "-"*30)
        
    except Exception as e:
        print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")