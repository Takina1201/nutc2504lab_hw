"""
LangChain é€²éšè¨è«– - å¯¦ä½œ(ch4-1)
ä½¿ç”¨ LCEL (LangChain Expression Language) çš„ chain å¯«æ³•

API: https://ws-02.wade0426.me/v1
Model: google/gemma-3-27b-it
"""

# ============================================================
# Import æ‰€æœ‰å¿…è¦çš„å‡½å¼åº«
# ============================================================
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
import json


# ============================================================
# 1. å®šç¾©å·¥å…· (Tool)
# ============================================================

@tool
def extract_order_data(name: str, phone: str, product: str, quantity: int, address: str):
    """
    è³‡æ–™æå–å°ˆç”¨å·¥å…·ã€‚
    å°ˆé–€ç”¨æ–¼å¾éçµæ§‹åŒ–æ–‡æœ¬ä¸­æå–è¨‚å–®ç›¸é—œè³‡è¨Šï¼ˆå§“åã€é›»è©±ã€å•†å“ã€æ•¸é‡ã€åœ°å€ï¼‰ã€‚
    """
    return {
        "name": name,
        "phone": phone,
        "product": product,
        "quantity": quantity,
        "address": address
    }


# ============================================================
# 2. è¨­å®š LLM
# ============================================================

llm = ChatOpenAI(
    base_url="https://ws-02.wade0426.me/v1",
    api_key="",  # KEY ç•™ç©º
    model="google/gemma-3-27b-it",
    temperature=0
)


# ============================================================
# 3. è¨»å†Šå·¥å…·
# ============================================================

llm_with_tools = llm.bind_tools([extract_order_data])


# ============================================================
# 4. å»ºç«‹ Prompt Template
# ============================================================

prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€å€‹ç²¾æº–çš„è¨‚å–®ç®¡ç†å“¡ï¼Œè«‹å¾å°è©±ä¸­æå–è¨‚å–®è³‡è¨Šã€‚"),
    ("user", "{user_input}")
])


# ============================================================
# 5. å®šç¾©æå–å·¥å…·åƒæ•¸çš„å‡½æ•¸
# ============================================================

def extract_tool_args(ai_message):
    """å¾ AI å›æ‡‰ä¸­æå–å·¥å…·å‘¼å«çš„åƒæ•¸"""
    if ai_message.tool_calls:
        return ai_message.tool_calls[0]['args']
    return None


# ============================================================
# 6. å»ºç«‹ Chain (ä½¿ç”¨ LCEL çš„ pipe èªæ³•)
# ============================================================

chain = prompt | llm_with_tools | extract_tool_args


# ============================================================
# 7. åŸ·è¡Œæ¸¬è©¦
# ============================================================

if __name__ == "__main__":
    # æ¸¬è©¦ç”¨çš„ç”¨æˆ¶è¼¸å…¥
    user_text = "ä½ å¥½ï¼Œæˆ‘æ˜¯é™³å¤§æ˜ï¼Œé›»è©±æ˜¯ 0912-345-678ï¼Œæˆ‘æƒ³è¦è¨‚è³¼ 3 å°ç­†è¨˜å‹é›»è…¦ï¼Œä¸‹é€±äº”é€åˆ°å°ä¸­å¸‚åŒ—å€ã€‚"
    
    print("=" * 60)
    print("ğŸ“ ç”¨æˆ¶è¼¸å…¥:")
    print(user_text)
    print("=" * 60)
    
    # åŸ·è¡Œ chain
    result = chain.invoke({"user_input": user_text})
    
    # é¡¯ç¤ºçµæœ
    if result:
        print("âœ… æå–æˆåŠŸ:")
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        print("âŒ æå–å¤±æ•—")